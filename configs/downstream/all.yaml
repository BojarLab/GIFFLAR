seed: 42
# root_dir: /scratch/SCRATCH_SAS/roman/Gothenburg/GIFFLAR/data
# logs_dir: /scratch/SCRATCH_SAS/roman/Gothenburg/GIFFLAR/logs
root_dir: /home/daniel/Data1/roman/GIFFLAR/data
logs_dir: /home/daniel/Data1/roman/GIFFLAR/logs
datasets:
  #- name: Immunogenicity
  #  task: classification
  #- name: Glycosylation
  #  task: classification
  - name: Tissue
    task: multilabel
  - name: Taxonomy_Domain
    task: multilabel
  - name: Taxonomy_Kingdom
    task: multilabel
  - name: Taxonomy_Phylum
    task: multilabel
  - name: Taxonomy_Class
    task: multilabel
  - name: Taxonomy_Order
    task: multilabel
  - name: Taxonomy_Family
    task: multilabel
  - name: Taxonomy_Genus
    task: multilabel
  - name: Taxonomy_Species
    task: multilabel
pre-transforms:
  GIFFLARTransform:
  GNNGLYTransform:
  ECFPTransform:
  SweetNetTransform:
  RGCNTransform:
  PyTorchRGCNTransform:
  RandomWalkPE:
    dim: 20
    individual: False
  LaplacianPE:
    dim: 20
    individual: False
model:
  #- name: rf
  #  n_estimators: 500
  #  n_jobs: -1
  #  random_state: 42
  #- name: svm
  #  random_state: 42
  #- name: xgb
  #  random_state: 42
  - name: mlp
    feat_dim: 1024
    hidden_dim: 1024
    batch_size: 256
    num_layers: 3
    epochs: 100
    patience: 30
    learning_rate: 0.001
    optimizer: Adam
  #- name: sweetnet
  #  feat_dim: 128
  #  hidden_dim: 1024
  #  batch_size: 512
  #  num_layers: 16
  #  epochs: 100
  #  patience: 30
  #  learning_rate: 0.001
  #  optimizer: Adam
  #  suffix:
  #- name: gnngly
  #  feat_dim: 128
  #  hidden_dim: 1024
  #  batch_size: 512
  #  num_layers: 8
  #  epochs: 100
  #  patience: 30
  #  learning_rate: 0.001
  #  optimizer: Adam
  #  suffix:
  #- name: rgcn
  #  feat_dim: 128
  #  hidden_dim: 1024
  #  batch_size: 256
  #  num_layers: 8
  #  epochs: 100
  #  learning_rate: 0.001
  #  optimizer: Adam
  #  suffix:
  #- name: gifflar
  #  feat_dim: 128
  #  hidden_dim: 1024
  #  batch_size: 256
  #  num_layers: 8
  #  epochs: 100
  #  learning_rate: 0.001
  #  optimizer: Adam
  #  pooling: global_mean
  #  suffix: _128_8_gp
